{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "dataInputPath='data/volumes'\n",
    "imagePathInput=os.path.join(dataInputPath,'img/')\n",
    "maskPathInput=os.path.join(dataInputPath,'mask/')\n",
    "\n",
    "dataOutputPath='data/slices'\n",
    "imageSliceOutput=os.path.join(dataOutputPath,'img/')\n",
    "maskSliceOutput=os.path.join(dataOutputPath,'mask')\n",
    "imgPath=os.path.join(imagePathInput,'volume-0.nii')\n",
    "img=nib.load(imgPath).get_fdata()\n",
    "np.min(img),np.max(img),img.shape,type(img)\n",
    "\n",
    "\n",
    "maskPath=os.path.join(maskPathInput,'segmentation-0.nii')\n",
    "mask=nib.load(maskPath).get_fdata()\n",
    "np.min(mask),np.max(img),mask.shape,type(mask)\n",
    "imgSlice=mask[:,:,65]\n",
    "plt.imshow(imgSlice,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "HOUNSFIELD_MIN=-1000 ####### may be i will have to change these valuse accoriding to values of my images\n",
    "HOUNSFIELD_MAX=2000\n",
    "HOUNSFIELD_RANGE=HOUNSFIELD_MAX-HOUNSFIELD_MIN\n",
    "def normalizeImageIntensityRange(img):\n",
    "    img[img<HOUNSFIELD_MIN]=HOUNSFIELD_MIN\n",
    "    img[img>HOUNSFIELD_MAX]=HOUNSFIELD_MAX\n",
    "    return (img-HOUNSFIELD_MIN)/HOUNSFIELD_RANGE\n",
    "\n",
    "##this is used to normalze the images\n",
    "def readImageVolume(imgPath,normalize=False):\n",
    "    img=nib.load(imgPath).get_fdata()\n",
    "    if normalize:\n",
    "        return normalizeImageIntensityRange(img)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "#this is used to read the images\n",
    "\n",
    "def saveSlice(img,fname,path):\n",
    "    img=np.uint8(img*255)\n",
    "    fout=os.path.join(path,f'{fname}.png')\n",
    "    cv2.imwrite(fout,img)\n",
    "    print(f'[+] Slice saved:{fout}',end='\\r')\n",
    "SLICE_DECIMATE_IDENTIFIER=3\n",
    "SLICE_X=True\n",
    "SLICE_Y=True\n",
    "SLICE_Z=True\n",
    "def sliceAndSaveVolumeImage(vol,fname,path):\n",
    "    (dimx,dimy,dimz)=vol.shape\n",
    "    count=0\n",
    "    if SLICE_X:\n",
    "        count+=dimx\n",
    "        print('Slicing X:')\n",
    "        for i in range(dimx):\n",
    "            saveSlice(vol[i,:,:],fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_x',path)\n",
    "\n",
    "    \n",
    "    if SLICE_Y:\n",
    "        count+=dimy\n",
    "        print('Slicing Y:')\n",
    "        for i in range(dimy):\n",
    "            saveSlice(vol[:,i,:],fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_y',path)\n",
    "    \n",
    "    \n",
    "    if SLICE_Z:\n",
    "        count+=dimz\n",
    "        print('Slicing Z:')\n",
    "        for i in range(dimz):\n",
    "            saveSlice(vol[:,:,i],fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_z',path)\n",
    "    \n",
    "for index,filename in enumerate(sorted(glob.iglob(imagePathInput+'*.nii'))):\n",
    "    print('index of the file being sliced : ',index)\n",
    "    img=readImageVolume(filename,True)\n",
    "    print(filename,img.shape,np.sum(img.shape),np.min(img),np.max(img))\n",
    "    numofSlices=sliceAndSaveVolumeImage(img,'volume-'+str(index),imageSliceOutput)\n",
    "    print(f'\\n{filename},{numofSlices} slices created \\n')\n",
    "for index,filename in enumerate(sorted(glob.iglob(maskPathInput+'*.nii'))):\n",
    "    print('index of the file being sliced : ',index)\n",
    "    img=readImageVolume(filename,True)\n",
    "    print(filename,img.shape,np.sum(img.shape),np.min(img),np.max(img))\n",
    "    numofSlices=sliceAndSaveVolumeImage(img,'volume-'+str(index),maskSliceOutput)\n",
    "    print(f'\\n{filename},{numofSlices} slices created \\n')\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "\n",
    "SEED=909\n",
    "BATCH_SIZE_TRAIN=32\n",
    "BATCH_SIZE_TEST=32\n",
    "\n",
    "IMAGE_HEIGHT=40\n",
    "IMAGE_WIDTH=80\n",
    "IMG_SIZE=(IMAGE_HEIGHT,IMAGE_WIDTH)\n",
    "\n",
    "data_dir='data/slices/'\n",
    "data_dir_train=os.path.join(data_dir,'training')\n",
    "data_dir_train_image=os.path.join(data_dir_train,'img')\n",
    "data_dir_train_mask=os.path.join(data_dir_train,'mask')\n",
    "\n",
    "data_dir_test=os.path.join(data_dir,'test')\n",
    "data_dir_test_image=os.path.join(data_dir_test,'img')\n",
    "data_dir_test_mask=os.path.join(data_dir_test,'mask')\n",
    "\n",
    "\n",
    "def unet(n_levels,initial_features=32,n_blocks=2,kernel_size=3,pooling_size=2,in_channels=1,out_channels=1):\n",
    "    inputs=keras.layers.Input(shape=(IMAGE_HEIGHT,IMAGE_WIDTH,in_channels))\n",
    "    x=inputs\n",
    "\n",
    "    convpars=dict(kernel_size=kernel_size,activation='relu',padding='same')\n",
    "\n",
    "    #downstream\n",
    "    skips={}\n",
    "    for level in range(n_levels):\n",
    "        for _ in range(n_blocks):\n",
    "            x=keras.layers.Conv2D(initial_features*2**level,**convpars)(x)\n",
    "        if level<n_levels-1:\n",
    "            skips[level]=x\n",
    "            x=keras.layers.MaxPool2D(pooling_size)(x)\n",
    "\n",
    "    #upstream\n",
    "    for level in reversed(range(n_levels-1)):\n",
    "        x=keras.layers.Conv2DTranspose(initial_features*2**level,strides=pooling_size,**convpars)(x)\n",
    "        x=keras.layers.Concatenate()([x,skips[level]])\n",
    "        for _ in range(n_blocks):\n",
    "            x=keras.layers.Conv2D(initial_features*2**level,**convpars)(x)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #output\n",
    "    x=keras.layers.Conv2D(out_channels,kernel_size=1,activation='sigmoid',padding='same')(x)\n",
    "\n",
    "    return keras.Model(inputs=[inputs],outputs=[x],name=f'UNET_L{n_levels}-F{initial_features}')\n",
    "\n",
    "NUM_TRAIN=0\n",
    "NUM_TEST=0\n",
    "\n",
    "NUM_OF_EPOCHS=0\n",
    "\n",
    "\n",
    "EPOCHS_STEP_TRAIN=NUM_TRAIN//BATCH_SIZE_TRAIN\n",
    "EPOCHS_STEP_TEST=NUM_TEST//BATCH_SIZE_TEST\n",
    "\n",
    "model=unet(4)\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=EPOCHS_STEP_TRAIN,\n",
    "                    validation_steps=EPOCHS_STEP_TEST,\n",
    "                    epochs=NUM_OF_EPOCHS)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
